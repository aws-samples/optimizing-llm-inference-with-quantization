AWSTemplateFormatVersion: "2010-09-09"
Description: A CloudFormation template to deploy llama.cpp on EC2

Parameters:
  CidrBlock:
    AllowedPattern: '((\d{1,3})\.){3}\d{1,3}/\d{1,2}'
    Default: 0.0.0.0/0
    Description: "CIDR block allowed to access the instance (example: 10.0.0.0/16, 3.179.207.170/32)"
    Type: String
  Ec2InstanceType:
    Description: EC2 instance type
    Type: String
    Default: g6.xlarge
    AllowedValues:
      - g4dn.xlarge
      - g4dn.2xlarge
      - g4dn.4xlarge
      - g5.xlarge
      - g5.2xlarge
      - g5.4xlarge
      - g5.8xlarge
      - g5.12xlarge
      - g5.16xlarge
      - g5.24xlarge
      - g5.48xlarge
      - g6.xlarge
      - g6.2xlarge
      - g6.4xlarge
      - g6.8xlarge
      - g6.12xlarge
      - g6.16xlarge
      - g6.24xlarge
      - g6.48xlarge
  TextGenUIUser:
    Description: User for connecting to the text generation webui
    Type: String
    Default: User
  TextGenUIPw:
    Description: Password for connecting to the text generation webui
    Type: String
    Default: 1234

Mappings:
  AMIRegionMap: # Deep Learning AMI GPU PyTorch 1.13.1 (Ubuntu 20.04) 20230530
    ap-northeast-1:
      ami: ami-0ccc8cde8079fbd80
    ap-northeast-2:
      ami: ami-00122226b77d62386
    ap-northeast-3:
      ami: ami-0b5e04c3248a2bc7d
    ap-south-1:
      ami: ami-0cebcf5b9d60dc50f
    ap-southeast-1:
      ami: ami-07038c7683047a90a
    ap-southeast-2:
      ami: ami-0e60dbcf8a762bd42
    ca-central-1:
      ami: ami-0bb8c0d44f2294c3f
    eu-central-1:
      ami: ami-0c7d7e0e142f2d910
    eu-north-1:
      ami: ami-04475f6596ac5d1f1
    eu-west-1:
      ami: ami-01fdee7e51dee90e8
    eu-west-2:
      ami: ami-067ff71b3acc16362
    eu-west-3:
      ami: ami-076a0183aec528137
    sa-east-1:
      ami: ami-0b7bd63e402b4a99f
    us-east-1:
      ami: ami-0705983c654abda59
    us-east-2:
      ami: ami-0c7e25230b4705f1b
    us-west-1:
      ami: ami-0bb9ce46219e4fa5a
    us-west-2:
      ami: ami-078e2151eadb5c30c

Resources:
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for LlamaCpp WebUI EC2 instance
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: !Ref CidrBlock
          Description: Allow incoming HTTP traffic from the specified CIDR block
      Tags:
        - Key: Name
          Value: llamacpp

  InstallWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  InstallWaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: EC2Instance
    Properties:
      Handle: !Ref InstallWaitHandle
      Timeout: 1800
      Count: 1

  SSMIAMRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore

  EC2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: /
      Roles:
        - !Ref SSMIAMRole

  EC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      IamInstanceProfile: !Ref EC2InstanceProfile
      InstanceType: !Ref Ec2InstanceType
      ImageId: !FindInMap
        - AMIRegionMap
        - !Ref "AWS::Region"
        - ami
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 300
            VolumeType: gp3
      Tags:
        - Key: Name
          Value: llamacpp
      SecurityGroups:
        - Ref: SecurityGroup
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash -x

          sudo apt-get update
          sudo apt-get upgrade -y
          sudo apt install wget git python3 python3-venv build-essential net-tools -y

          # install git-lfs
          curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
          apt --fix-broken install -y
          sudo apt-get install git-lfs
          sudo -u ubuntu git lfs install --skip-smudge

          # install python 3.10
          add-apt-repository ppa:deadsnakes/ppa -y
          apt-get install python3.10 python3.10-venv python3.10-dev -y

          # clone llamacpp
          cd /home/ubuntu
          git clone https://github.com/ggerganov/llama.cpp.git

          # clone lm harness
          git clone https://github.com/EleutherAI/lm-evaluation-harness.git

          # clone text-generation-webui
          git clone https://github.com/oobabooga/text-generation-webui.git

          # install conda
          mkdir env
          cd env
          curl -sL "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh" > "Miniconda3.sh"
          bash Miniconda3.sh -b -u -p ./
          bin/conda init bash
          source etc/profile.d/conda.sh

          # create virtual environment
          conda create -n textgen python=3.10 -y
          conda create -n llamacpp python=3.10 -y
          conda create -n harness python=3.10 -y

          # install llama-cpp-python
          conda activate llamacpp
          sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test
          sudo apt update
          sudo apt install -y gcc-11 g++-11
          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 60 --slave /usr/bin/g++ g++ /usr/bin/g++-11
          pip install --upgrade pip
          pip install --upgrade setuptools wheel
          CUDACXX=/usr/local/cuda/bin/nvcc CMAKE_ARGS="-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=native" FORCE_CMAKE=1 pip install llama-cpp-python==0.2.25 --no-cache-dir --force-reinstall --upgrade
          pip install starlette-context pip install uvicorn pydantic-settings huggingface-hub fastapi sse_starlette
          conda deactivate

          # install llm evaluation harness
          cd ../lm-evaluation-harness
          conda activate harness
          python3 -m pip install -e .
          pip install -e .[zeno]
          pip install einops plotly orjson -U kaleido
          mkdir eval_results images
          conda deactivate

          # install llamacpp
          cd ../llama.cpp
          python3 -m venv llamacpp-venv
          source llamacpp-venv/bin/activate
          make LLAMA_CUBLAS=1
          python3 -m pip install -r requirements.txt
          deactivate

          # install text generation webui
          cd ../text-generation-webui
          conda activate textgen
          echo --listen --listen-port 80 --api --gradio-auth ${TextGenUIUser}:${TextGenUIPw} > CMD_FLAGS.txt
          pip install -r requirements.txt
          pip install -r extensions/openai/requirements.txt --upgrade
          curl -X PUT -H 'Content-Type:' --data-binary '{"Status" : "SUCCESS","Reason" : "Configuration Complete","UniqueId" : "EC2Instance","Data" : "Application has completed configuration."}' "${InstallWaitHandle}"

          python3 server.py --listen --listen-port 80 --api --gradio-auth ${TextGenUIUser}:${TextGenUIPw}

  EIP:
    Type: AWS::EC2::EIP
    Properties:
      Tags:
        - Key: Name
          Value: llamacpp

  EIPAssociation:
    Type: AWS::EC2::EIPAssociation
    Properties:
      AllocationId: !GetAtt EIP.AllocationId
      InstanceId: !Ref EC2Instance

Outputs:
  WebUiURL:
    Description: URL for Text Generation Web UI (available in 30 mins)
    Value: !Sub "http://${EIP}"
